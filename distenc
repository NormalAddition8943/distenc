#!/usr/bin/env python3
"""
Batch encode videos to x265 with crop detection and concurrency.
Uses token files in a shared directory to coordinate encoding jobs.

Usage:
    distenc --inputs <input_files>... --output-dir <output_dir> \
            --scratch-dir <scratch_dir> --token-dir <token_dir> \
            [--jobs <num>]
"""

import argparse
import asyncio
import glob
import json
import logging
import os
import re
import signal
import subprocess
import sys
import tempfile
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from shutil import which
from typing import Dict, List, Optional, Tuple, AsyncGenerator
import time


class EncodingStatus(Enum):
    """Status of encoding jobs."""

    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


@dataclass
class Config:
    """Configuration for video encoding."""

    # Video settings
    target_width: str = "-2"
    target_height: str = "720"
    video_bitrate_kbps: int = 800
    audio_bitrate_kbps: int = 80
    crop_samples: int = 5

    # Tool paths
    ffmpeg_path: str = "ffmpeg"
    ffprobe_path: str = "ffprobe"

    # x265 encoding parameters
    x265_params: str = (
        "hme=1:hme-search=hex,hex,umh:hme-range=25,25,26:subme=5:"
        "min-keyint=24:keyint=800:cbqpoffs=-3:crqpoffs=-3:rc-lookahead=48:"
        "aq-mode=4:aq-strength=1.0:aq-motion=1:qcomp=0.65:bframes=6:ref=4:"
        "rd=4:dynamic-rd=4:psy-rd=1.8:psy-rdoq=1.0:deblock=-3:"
        "tskip=1:tskip-fast=1:frame-threads=2:limit-sao=1:selective-sao=1:"
        "no-amp=1:no-rect=1:no-high-tier=1:hdr10-opt=1:vbv-maxrate=8000:vbv-bufsize=12000"
    )

    # Audio processing
    audio_filter: str = "dynaudnorm=threshold=-40dB,loudnorm=I=-15:TP=-1.0:LRA=12"

    @property
    def detect_filter(self) -> str:
        """Filter for crop detection."""
        return f"scale={self.target_width}:{self.target_height},cropdetect=round=2"


@dataclass
class CropParameters:
    """Crop detection results."""

    width: int
    height: int
    x: int
    y: int

    def to_filter_string(self, config: Config) -> str:
        """Convert to FFmpeg filter string."""
        return (
            f"zscale={config.target_width}:{config.target_height}:"
            f"filter=spline36:param_a=5,"
            f"crop={self.width}:{self.height}:{self.x}:{self.y},"
            f"cas=strength=0.13"
        )


@dataclass
class VideoInfo:
    """Information about a video file."""

    path: Path
    duration: Optional[float] = None
    has_dolby_vision: Optional[bool] = None
    crop_params: Optional[CropParameters] = None


@dataclass
class EncodingJob:
    """Represents a single encoding job."""

    input_path: Path
    output_path: Path
    token_path: Path
    temp_path: Optional[Path] = None
    status: EncodingStatus = EncodingStatus.PENDING
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    error_message: Optional[str] = None

    @property
    def duration(self) -> Optional[float]:
        """Get job duration if completed."""
        if self.start_time and self.end_time:
            return self.end_time - self.start_time
        return None


class FFmpegError(Exception):
    """Custom exception for FFmpeg-related errors."""

    pass


class VideoAnalyzer:
    """Analyzes video files for encoding parameters."""

    def __init__(self, config: Config):
        self.config = config
        self.logger = logging.getLogger(__name__)

    async def _run_command(
        self, cmd: List[str], timeout: int = 300
    ) -> subprocess.CompletedProcess:
        """Run command asynchronously with timeout."""
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                stdin=asyncio.subprocess.DEVNULL,
                env={**os.environ, "TERM": "dumb"},
            )
            stdout, stderr = await asyncio.wait_for(
                process.communicate(), timeout=timeout
            )

            # Create a CompletedProcess-like object
            result = subprocess.CompletedProcess(
                cmd, process.returncode, stdout, stderr
            )
            if result.returncode != 0:
                raise FFmpegError(
                    f"Command failed: {' '.join(cmd)}\nStderr: {stderr.decode()}"
                )
            return result

        except asyncio.TimeoutError:
            if process:
                process.terminate()
                await process.wait()
            raise FFmpegError(f"Command timed out after {timeout}s: {' '.join(cmd)}")

    async def get_video_info(self, path: Path) -> VideoInfo:
        """Get comprehensive video information."""
        info = VideoInfo(path)

        # Get duration and Dolby Vision info in parallel
        duration_task = self._get_duration(path)
        dv_task = self._has_dolby_vision(path)

        info.duration, info.has_dolby_vision = await asyncio.gather(
            duration_task, dv_task, return_exceptions=True
        )

        # Handle exceptions
        if isinstance(info.duration, Exception):
            self.logger.warning(f"Could not get duration for {path}: {info.duration}")
            info.duration = None
        if isinstance(info.has_dolby_vision, Exception):
            self.logger.warning(
                f"Could not check Dolby Vision for {path}: {info.has_dolby_vision}"
            )
            info.has_dolby_vision = False

        return info

    async def _get_duration(self, path: Path) -> float:
        """Get video duration in seconds."""
        cmd = [
            self.config.ffprobe_path,
            "-v",
            "error",
            "-select_streams",
            "v:0",
            "-show_entries",
            "format=duration",
            "-of",
            "default=noprint_wrappers=1:nokey=1",
            str(path),
        ]
        result = await self._run_command(cmd)
        return float(result.stdout.decode().strip())

    async def _has_dolby_vision(self, path: Path) -> bool:
        """Check if video has Dolby Vision metadata."""
        cmd = [
            self.config.ffprobe_path,
            "-v",
            "quiet",
            "-select_streams",
            "v:0",
            "-show_streams",
            "-print_format",
            "json",
            str(path),
        ]
        result = await self._run_command(cmd)
        data = json.loads(result.stdout.decode())
        stream = data.get("streams", [{}])[0]
        side_data_list = stream.get("side_data_list", [])
        return any(
            sd.get("side_data_type") == "DOVI configuration record"
            for sd in side_data_list
        )

    async def _detect_crop_at_timestamp(
        self, path: Path, timestamp: float
    ) -> Optional[Tuple[int, int, int, int]]:
        """Detect crop parameters at a specific timestamp."""
        cmd = [
            self.config.ffmpeg_path,
            "-hide_banner",
            "-ss",
            f"{timestamp:.3f}",
            "-i",
            str(path),
            "-frames:v",
            "5",
            "-vf",
            self.config.detect_filter,
            "-f",
            "null",
            "/dev/null" if os.name != "nt" else "NUL",
        ]

        try:
            result = await self._run_command(cmd, timeout=60)
        except FFmpegError:
            return None

        stderr = result.stderr.decode(errors="ignore")
        matches = re.findall(r"crop=(\d+):(\d+):(\d+):(\d+)", stderr)
        return tuple(map(int, matches[-1])) if matches else None

    async def detect_crop_parameters(self, video_info: VideoInfo) -> CropParameters:
        """Detect optimal crop parameters by sampling multiple timestamps."""
        if not video_info.duration:
            raise FFmpegError("Cannot detect crop without video duration")

        interval = video_info.duration / self.config.crop_samples
        timestamps = [i * interval for i in range(self.config.crop_samples)]

        # Detect crops at all timestamps concurrently
        crop_tasks = [
            self._detect_crop_at_timestamp(video_info.path, ts) for ts in timestamps
        ]
        crop_results = await asyncio.gather(*crop_tasks, return_exceptions=True)

        # Process results
        valid_crops = [
            result
            for result in crop_results
            if not isinstance(result, Exception) and result is not None
        ]

        if not valid_crops:
            raise FFmpegError("No crop parameters detected")

        # Find bounding box
        min_x = min(crop[2] for crop in valid_crops)  # x offset
        min_y = min(crop[3] for crop in valid_crops)  # y offset
        max_x = max(crop[2] + crop[0] for crop in valid_crops)  # x + width
        max_y = max(crop[3] + crop[1] for crop in valid_crops)  # y + height

        crop_params = CropParameters(
            width=max_x - min_x, height=max_y - min_y, x=min_x, y=min_y
        )

        self.logger.info(
            f"Detected crop {crop_params.width}:{crop_params.height}:"
            f"{crop_params.x}:{crop_params.y} for {video_info.path.name}"
        )

        return crop_params


class VideoEncoder:
    """Handles video encoding operations."""

    def __init__(self, config: Config, analyzer: VideoAnalyzer):
        self.config = config
        self.analyzer = analyzer
        self.logger = logging.getLogger(__name__)

    def _build_encoding_commands(
        self, job: EncodingJob, video_info: VideoInfo
    ) -> Tuple[List[str], List[str]]:
        """Build the two-pass encoding commands."""
        vf_filter = video_info.crop_params.to_filter_string(self.config)
        dolby_vision_flag = "1" if video_info.has_dolby_vision else "0"

        assert job.temp_path is not None
        stats_path = job.temp_path.with_suffix(".stats")

        base_cmd = [
            self.config.ffmpeg_path,
            "-hide_banner",
            "-stats",
            "-y",
            "-i",
            str(job.input_path),
            "-vf",
            vf_filter,
            "-dolbyvision",
            dolby_vision_flag,
            "-c:v",
            "libx265",
            "-pix_fmt",
            "yuv420p10le",
            "-b:v",
            f"{self.config.video_bitrate_kbps}k",
            "-preset",
            "slower",
        ]

        # First pass (analysis)
        first_pass = base_cmd + [
            "-x265-params",
            f"pass=1:stats={stats_path}:no-slow-firstpass=1:{self.config.x265_params}",
            "-an",
            "-f",
            "null",
            "/dev/null" if os.name != "nt" else "NUL",
        ]

        # Second pass (final encode)
        second_pass = base_cmd + [
            "-x265-params",
            f"pass=2:stats={stats_path}:{self.config.x265_params}",
            "-filter:a",
            self.config.audio_filter,
            "-ac",
            "2",
            "-c:a",
            "libopus",
            "-b:a",
            f"{self.config.audio_bitrate_kbps}k",
            "-frame_duration",
            "60",
            str(job.output_path),
        ]

        return first_pass, second_pass

    async def _run_encoding_pass(
        self, cmd: List[str], job: EncodingJob, pass_name: str
    ):
        """Run a single encoding pass with logging."""
        self.logger.info(f"Starting {pass_name} for {job.input_path.name}")

        with job.token_path.open("a") as log_file:
            process = await asyncio.create_subprocess_exec(
                *cmd, stdout=log_file, stderr=log_file, stdin=asyncio.subprocess.DEVNULL
            )
            await process.wait()

        if process.returncode != 0:
            raise FFmpegError(f"{pass_name} failed with code {process.returncode}")

    async def encode_video(self, job: EncodingJob) -> None:
        """Perform complete video encoding."""
        job.start_time = time.time()
        job.status = EncodingStatus.IN_PROGRESS

        try:
            # Analyze video
            video_info = await self.analyzer.get_video_info(job.input_path)
            if not video_info.duration:
                raise FFmpegError("Could not determine video duration")

            # Detect crop parameters
            video_info.crop_params = await self.analyzer.detect_crop_parameters(
                video_info
            )

            # Build encoding commands
            first_pass, second_pass = self._build_encoding_commands(job, video_info)

            # Execute two-pass encoding
            await self._run_encoding_pass(first_pass, job, "first pass")
            await self._run_encoding_pass(second_pass, job, "second pass")

            job.status = EncodingStatus.COMPLETED
            self.logger.info(f"Encoding completed: {job.input_path.name}")

        except Exception as e:
            job.status = EncodingStatus.FAILED
            job.error_message = str(e)
            self.logger.error(f"Encoding failed for {job.input_path.name}: {e}")

            # Cleanup failed output
            job.output_path.unlink(missing_ok=True)
            if job.token_path.exists():
                job.token_path.rename(job.token_path.with_suffix(".error_log"))

        finally:
            job.end_time = time.time()

            # Cleanup temporary files
            if job.temp_path:
                for temp_file in glob.glob(str(job.temp_path) + "*"):
                    Path(temp_file).unlink(missing_ok=True)
                job.temp_path = None

class BatchProcessor:
    """Orchestrates batch processing with proper resource management."""

    def __init__(self, config: Config):
        self.config = config
        self.analyzer = VideoAnalyzer(config)
        self.encoder = VideoEncoder(config, self.analyzer)
        self.logger = logging.getLogger(__name__)
        self._shutdown_event = asyncio.Event()
        self._active_jobs: Dict[Path, EncodingJob] = {}

    def _setup_signal_handlers(self):
        """Setup graceful shutdown signal handlers."""
        for sig in [signal.SIGINT, signal.SIGTERM]:
            signal.signal(sig, self._signal_handler)

    def _signal_handler(self, signum, frame):
        """Handle shutdown signals."""
        self.logger.info(f"Received signal {signum}, initiating shutdown...")
        self._shutdown_event.set()

    def _check_dependencies(self) -> bool:
        """Verify required tools are available."""
        missing_tools = []
        for tool in [self.config.ffmpeg_path, self.config.ffprobe_path]:
            if not which(tool):
                missing_tools.append(tool)
                self.logger.error(f"Required tool not found: {tool}")

        if missing_tools:
            self.logger.error("Please install missing tools and ensure they're in PATH")
            return False

        return True

    def _create_job_template(
        self, input_path: Path, output_dir: Path, token_dir: Path
    ) -> EncodingJob:
        """Create a job template without claiming it yet."""
        token_path = (token_dir / input_path.name).with_suffix(".token")
        output_path = output_dir / input_path.name

        return EncodingJob(
            input_path=input_path,
            output_path=output_path,
            token_path=token_path,
        )

    def _try_claim_job(self, job: EncodingJob, scratch_dir: Path) -> bool:
        """Try to claim a job by creating its token. Returns True if successfully claimed."""
        # Check if already processed
        if job.output_path.exists():
            self.logger.info(f"Output already exists: {job.output_path.name}")
            # Create token to mark as done
            job.token_path.touch()
            return False

        # Try to claim the job atomically
        try:
            # Use exclusive creation to prevent race conditions
            with job.token_path.open("x") as f:
                f.write(f"Claimed by PID {os.getpid()} at {time.time()}\n")
            
            # Create temporary file now that we've claimed the job
            with tempfile.NamedTemporaryFile(dir=scratch_dir, delete=False) as tmp:
                job.temp_path = Path(tmp.name)
            
            self.logger.info(f"Successfully claimed job: {job.input_path.name}")
            return True
            
        except FileExistsError:
            # Another process already claimed this job
            self.logger.info(f"Job already claimed by another process: {job.input_path.name}")
            return False

    @asynccontextmanager
    async def _job_context(self, job: EncodingJob) -> AsyncGenerator[EncodingJob, None]:
        """Context manager for job lifecycle."""
        self._active_jobs[job.input_path] = job
        try:
            yield job
        finally:
            self._active_jobs.pop(job.input_path, None)
            # Cleanup token on failure
            if job.status == EncodingStatus.FAILED and job.token_path.exists():
                job.token_path.unlink(missing_ok=True)

    async def _process_job(self, job: EncodingJob, semaphore: asyncio.Semaphore, scratch_dir: Path):
        """Process a single encoding job with concurrency control."""
        async with semaphore:
            if self._shutdown_event.is_set():
                job.status = EncodingStatus.SKIPPED
                return

            # Try to claim the job just before processing
            if not self._try_claim_job(job, scratch_dir):
                job.status = EncodingStatus.SKIPPED
                return

            async with self._job_context(job):
                await self.encoder.encode_video(job)

    async def process_batch(
        self,
        input_files: List[Path],
        output_dir: Path,
        scratch_dir: Path,
        token_dir: Path,
        max_workers: int = 1,
    ) -> bool:
        """Process batch of video files asynchronously."""
        if not self._check_dependencies():
            return False

        # Create directories
        for directory in [output_dir, scratch_dir, token_dir]:
            directory.mkdir(parents=True, exist_ok=True)

        # Create job templates (don't claim them yet)
        jobs = []
        for input_file in input_files:
            if not input_file.is_file():
                self.logger.warning(f"Skipping non-file: {input_file}")
                continue

            job = self._create_job_template(input_file, output_dir, token_dir)
            jobs.append(job)

        if not jobs:
            self.logger.info("No jobs to process")
            return True

        self.logger.info(f"Found {len(jobs)} potential jobs with {max_workers} workers")

        # Process jobs with concurrency control
        semaphore = asyncio.Semaphore(max_workers)
        tasks = [self._process_job(job, semaphore, scratch_dir) for job in jobs]

        try:
            await asyncio.gather(*tasks)
        except KeyboardInterrupt:
            self.logger.info("Processing interrupted by user")
            self._shutdown_event.set()

        # Report results
        completed = sum(1 for job in jobs if job.status == EncodingStatus.COMPLETED)
        failed = sum(1 for job in jobs if job.status == EncodingStatus.FAILED)
        skipped = sum(1 for job in jobs if job.status == EncodingStatus.SKIPPED)

        self.logger.info(
            f"Batch complete: {completed} succeeded, {failed} failed, {skipped} skipped"
        )
        return failed == 0


def setup_logging(verbose: bool = False):
    """Setup logging configuration."""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.StreamHandler(sys.stdout),
        ],
    )


async def main_async():
    """Async main function."""
    parser = argparse.ArgumentParser(
        description="Batch x265 encode with crop detection, Dolby Vision, and async concurrency."
    )
    parser.add_argument(
        "-i",
        "--inputs",
        nargs="+",
        type=Path,
        required=True,
        help="Input video files to encode",
    )
    parser.add_argument(
        "-o",
        "--output-dir",
        type=Path,
        required=True,
        help="Directory for encoded output files",
    )
    parser.add_argument(
        "-s",
        "--scratch-dir",
        type=Path,
        required=True,
        help="Directory for temporary files during encoding",
    )
    parser.add_argument(
        "-t",
        "--token-dir",
        type=Path,
        required=True,
        help="Directory for coordination token files",
    )
    parser.add_argument(
        "-j", "--jobs", type=int, default=1, help="Number of concurrent encoding jobs"
    )
    parser.add_argument(
        "-v", "--verbose", action="store_true", help="Enable verbose logging"
    )

    args = parser.parse_args()

    setup_logging(args.verbose)

    config = Config()
    processor = BatchProcessor(config)
    processor._setup_signal_handlers()

    success = await processor.process_batch(
        args.inputs, args.output_dir, args.scratch_dir, args.token_dir, args.jobs
    )

    return 0 if success else 1


def main():
    """Main entry point."""
    try:
        exit_code = asyncio.run(main_async())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nInterrupted by user")
        sys.exit(1)


if __name__ == "__main__":
    main()